# DAY 1


## 쉬는 시간

15분

## 제일 중요한 점심시간

점심시간 길이: 01시 20분

11:50 ~ 


## 오픈스택 개념

1. 도메인

오픈스택에서 묶음을 나누는 영역. "프로젝트", "사용자"와 같은 자원들이 분류가 됨.

2. stack

- undercloud(인프라)에서는 "director heat"에 사용하는 "stack"를 말한다. 이를 통해서 오픈스택 노드 및 클러스터 구성(서비스 오픈스택 클러스터). "director"는 오픈스택 설치 관리자를 이야기 한다.

- 오픈스택 플랫폼에서는 "프로젝트"에서 생성되는 자원을 자동화 한다. 이 부분도 "stack"라고 부른다.

- "가상머신(virtual machine, general)"은 "instance(concept)", "server(cli)"

- "heat(stack)"서비스가 쿠버네티스의 "deployment"와 같은 역할을 한다.

```bash

undercloud ==  adminstrator == kubeadm(dhcp,tftp,raw image) 
               director     == heat(os, openstack, network)
               

overcloud  == [K8S_CLUSTER] == deployment[K8S_RESOURCE['pod','deployment','replicaset']]
              [OSP_CLUSTER] == heat[OSP_RESOURCE['server','network','image']]
```
## 오픈스택 서비스

1. 오픈스택 서비스는 대다수가 포드만 컨테이너로 제공.
2. 몇몇 호스트 서비스는 존재. 스토리지나 혹은 네트워크 몇몇 프로그램은 호스트에 설치 및 구성.
3. 컨테이너 시작은 systemd에서 서비스 형태로 구성이 되어 있고, 이를 panuch가 관리.


## 오픈스택 관리 명령어

더 이상 "openstack-service", "opstack-status"명령어는 컨테이너 기반 오픈스택에서 시용이 불가능. 

관리를 위해서는 'podman', 'systemctl'명령어로 오픈스택 서비스 관리. 로그 확인 및 운영을 위해서 'journalctl'도 필요함.

```bash
podman ps

podman container ls --format="{{ .Names }}" | grep -i nova

```
# DAY 2

## 정리

1. 오픈스택 기반 기술

일반적으로 리눅스 가상화 이야기 할때 "QEMU", "KVM". 

QEMU: "Machine Emulator"기능 제공.(CPU, DISK, NET...virtio driver)
KVM: Kernel based Virtual Machine. CPU에서 제공하는 전가상화 기능을 활성화. "qemu-ga"를 통해서 통합이 되어 있음. 
libvirt: "library virtualization daemon"가상머신 및 가상 자원을 생성 및 관리.

Podman: Pod Manager. 이전에는 docker로 생성 및 관리.

.servce: 대다수 오픈스택은 컨테이너 서비스는 systemd의 ".service"유닛으로 관리 및 운영. "/etc/systemd/system"에서 관리가 되고 있음.

- 가상화(qemu/kvm, libvirt)
- podman container runtime
- systemctl(systemd), journalctl(systemd-jounald)


2. domain operator

관리자/사용자로 나누어짐.

## 오픈스택 관리자/사용자

### 오픈스택 인프라 관리자(openstack SRE)

- 운영체제
- 자동화
- 네트워크
- 보안
- 스토리지
- 기타 하드웨어

모든 사용자가 오픈스택 도메인에는 포함 되지는 않음. 실질적으로는 오픈스택 명령어 및 사용에는 많이 관여하지는 않음.

### 오픈스택 운영자(openstack operator)

오픈스택에서 사용되는 사용자 및 자원을 전체적으로 운영 및 관리.

### 오픈스택 사용자(openstack user)

실제 오픈스택 자원 사용자. 

1. 개발자
2. 고객
3. 내부 서비스 

## 오픈스택 코어 서비스

- controller(keystone, glance, cinder, nova-api, neutron-api)
- compute(nova-compte)
- network(OVS+OVN)
- storage(RHOSP: ceph-storage)

오픈스택 서비스를 구성하기 위해서 최소한 아래와 같은 서비스가 설치가 되어야 한다.

1. nova(instance, flavor)
2. keystone(ident)
3. glance(vm image)
4. cinder(vm volume)
5. neutron(vm network)

## 오픈스택 설치도구

1. director(TripeO, hardware provisioning)
2. heat, kolla("Ansible", "shell script", "puppet", OpenStack Deployment)
3. kolla(Ansible, openstack deployment)


## Size for PoC

- controller: 3대 이상.
- compute: 2대 이상.
- network: "compute node"에 포함.
- storage: "ceph", "LVM2", "NFS"

# DAY 3

1. 라우터: OVN이 구성 및 생성. 이전에는 iptables를 사용. 현재는 nftables로 사용. 하지만, OVN은 소프트웨어적으로 라우팅을 구성 및 생성후 오픈스택 가상머신에 전달.

2. 스위치: OVN이 구성 및 생성. 이전에는 kernel namespace를 통해서 구현. 
3. DHCP: "dnsmasq"통해서 구현 및 제공. 이때는, 탭 장치를 통해서 네임스페이스 영역에 데이터를 전달.  현재는 OVN에서 구성 및 제공.
4. 허브/스위치: 오픈스택에서는 "허브/스위치"는 구별하지 않음. 이전에는 네임스페이스를 통해서 구성 및 제공. 현재는 OVN에서 구성 및 제공.
5. 브릿지: vpair, veth, tap 장치를 통해서 가상 브릿지 장치를 구성 및 제공. 일종의 patch cable과 같은 역할.
6. ML2/ML3: Module Layer2/3.


## provider network

1. flat

프로젝트 내부에 있는 가상머신들이, 외부에서 접근은 되지 않지만, 외부에서 패키지와 같은 자원을 내려받기 하기 위해서는, "SNAT"으로 구성해서 사용이 가능하도록 한다.

2. provider(vlan)

일반적으로 "프로바이너 네트워크로 구성이 되었어요"라고 말하면, 보통은 "vlan"기반으로 직접 스위치에 연결된 구성.


## image

1. qcow2(qcow3)

qcow2(3)는 오픈스택에서 표준으로 사용하는 가상머신 이미지. 

2. raw

표준 가상머신 이미지. 속도 및 호환성은 좋지만, 문제점은 관리 기능 및 이미지 기능이 부족.

# DAY 4

# DAY 5

## 네트워크

1. 터널링 네트워크(geneve)
2. 테넌트 네트워크(VNID, br-int(bridge))
3. OVS/OVN 네트워크(브릿지 및 포트 생성 및 구성)

local: 테스트 용도 혹은 AIO에서 사용.
flat: NAT네트워크 용도로 사용. 
VLAN: provider(physical) network, teanent(project) network에서 사용.

GRE, VXLAN: 터널링 프로토콜.


## DHCP

teanent network: OVN에서 DHCP를 제공.
provider network: 물리적인 네트워크에서 DHCP제공. 네트워크 생성 시, DHCP활성화 하시는 경우, provider network에 DHCP 공급.