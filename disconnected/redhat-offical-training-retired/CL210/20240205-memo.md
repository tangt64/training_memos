# DAY 1

## 오픈스택 CL210 과정

__강사:__ 최국현

__이메일:__ tang@linux.com

[메모파일](https://github.com/tangt64/training_memos/blob/main/redhat-offical-training/CL210/20240205-memo.md)

[화이트 보드](https://wbd.ms/share/v2/aHR0cHM6Ly93aGl0ZWJvYXJkLm1pY3Jvc29mdC5jb20vYXBpL3YxLjAvd2hpdGVib2FyZHMvcmVkZWVtLzVkYTkxMDdmNDk4ZTQwMDJhY2JmN2Y5ZWQwMDhjYTk5X0JCQTcxNzYyLTEyRTAtNDJFMS1CMzI0LTVCMTMxRjQyNEUzRF8wZDRiOGUyMy1iMjk3LTQwYjItOTIyMS04MTEyYzQzZGRkMGI=)

점심시간: 12전후

쉬는시간: 10~15분정도


## 랩 소개

```
RHEL/Rocky
Podman/Docker

RHEL 8<=
Podman 
```

- student/student
- root/redhat

1. 터미널 하나 실행
2. 'sudo dnf install gnome-tweaks -y'
3. 'gnome-tweaks'
4. 'extension -> Application Menu, Desktop Icons, Windows List'
5. 'Window -> Min/Max Window Size' 


## 오픈스택 자동화

>자동화 엔지니어 또는 DevOps 엔지니어

1. Ansible/terraform/salt
2. OpenStack CI/CD(ZUUL)
3. Heat
4. API(OpenStack)
5. Image Build(OS+APP+LIB)

## 지나가면서...(운영체제)

Network(NetworkManager, systemd-networked)
---

__"NetworkManager"__모든 배포판에서 지원 및 사용. 최종적으로는 모든 배포판은 __"systemd-networked"__으로 통합. 앞으로는 __ifcfg-rh__형식은 지원하지 않음.

추후에 모든 네트워크는 시스템 블록인 "systemd"기반인 __"systemd-networkd"__ 로 통합. 현재 모든 배포판에서 사용이 가능.

[네트워크 매니저 마이그레이션 기능](https://opensource.com/article/22/8/migrate-networkmanager-keyfiles-configuration)

[systemd 네트워크](https://www.freedesktop.org/software/systemd/man/latest/)systemd.network.html


NTP(systemd-timedated)
---
1. NTPD
2. Chornyd

[systemd NTP](https://www.freedesktop.org/software/systemd/man/latest/systemd-timesyncd.service.html)

## podman


```bash
cd /etc/containers/
> policy.json     ## redhat.com위주로 구성 및 설정
> registries.conf

podman images
podman pods ls          ## 포드 조회
podman container ls       ## 컨테이너 조회
podman ps


## 컨테이너 상태 정보 저장위치

cd /var/lib/containers/storage/
> overlay             ## 컨테이너 모든 정보는 여기에 저장이 되어 있음
> overlay-containers
> overlay-images
```
1. POD+Container(POD(APP, Init 1))
2. dumb-init(syscall, Init 1)
> systemd. openstack-nova-compute.service | systemctl start httpd


# DAY 2

## 오픈스택 백업

1. 데이타베이스 백업(mariadb, mysql)
2. 설정파일(control-plane, compute, neutron backup)
3. 스토리지 백업 대상에서 제외
4. 이미지 백업(glance에 존재하는 이미지)
5. OS설정 부분(RHEL+UBI+Podman)


1. YAML: 인프라
2. TOML: 설정
3. JSON: 데이터


```bash
## BOOTSTRAPING
0. DOMAIN(testDomain)     ---> openstack domain create testSDS
1. ROLE(testRole)         ---> openstack role create testRole --domain testSDS
2. USER(testUser)         ---> openstack user create testUser --domain testSDS
3. PROJECT(testProject)   ---> openstack project create testProject --domain testSDS


ASSIGNMENT=ROLE{USER+PROJECT}  ---> openstack role add --user testUser --project testProject testRole

                               { REGION }
                                   |
                                   |        
                                RegionOne
                                   |
                                   |
                               { DOMAIN } ---> [SDS]
                                   |
                                   |
                             D(d)efault ---> { USER }
                                   /    ---> { PROJECT }
                                  /
                               { ROLE }
                                /
                               /   
         .---> openstack role create freeuser     ## 메타정보만 생성
        /                            --------
		OSP(ROLE)                          /
        \                           mapping
         \                           /
          `---> policy.json ---> policy.yaml
                                   [RBAC]
                                      - swiftoperator
                                      - member(_member_)
                                      - service
                                      - admin


                 ROLE --- GROUP --- USER(s)
                                     --group testGroup

                                    100(user_rbac)

```


qemu: 예물레이터 
- device
  + disk(qcow2-3, raw)
  + cpu
  + memory
  + bios
  + mainboard
  + nic(full)


>Near-raw performance, competitive with QED.
>Fully QCOW2 backwards-compatible feature set.
>Extensibility to tackle current and future storage virtualization challenges.


```bash

Copy On Write
Copy On Read

                        
                      [ volume ]   --- { cinder }
                           ^
                           |
                           |
                 .----> instance x 10 (COW)
                /
             backing file(device)
              /
+----------------+
|   base image   | COR
+----------------+

qemu-img info blahblah.qcow2
> format: qcow3
> virtio, para-virtualization driver 


qemu, libvirtd
```


kvm: 가상화 가속기(intel/amd)
- kvm.ko(irqbypass)
  + kvm_intel
  + kvm_amd

```bash


qemu-img

````

# DAY 3

## 디스크 이미지 빌드 도구

공통사항
---
가상머신 이미지를 다루는 도구는 __"libguestfs-tools-c"__ 으로 제공. 이 명령어들은 보통 __'virt-????'__으로 시작.



1. diskimage-builder

디렉터리 프레임워크 기반. 

2. oz

XML(DOM)를 통해서 이미지 빌드 정보. 

3. virt-builder
---
내부 혹은 외부 저장소에서 표준 이미지를 내려받기 후, 옵션에 따라서 패키지 설치 및 구성을 진행. 

```bash
virt-builder --list
virt-builder alma-8.5 -o alma.raw

sudo LIBGUESTFS_BACKEND=direct virt-builder --size 8G --format qcow2 --root-password password:redhat alma-8.5 --hostname build.example.com --install httpd,vsftpd -o alma-8G.qcow2
```


4. manual(수동으로 구성)

libvirt, virt-install 이미지 생성 후, 수동으로 가상머신 이미지 구성.

```bash
dnf install libvirt-client virt-install
virsh net-list
virsh pool-list 
mv alma-8.5.qcow2 /var/lib/libvirt/images/alma.qcow2
virt-install --name test-alma --memory 1024 --vcpu 2 --disk=path=/var/lib/libvirt/images/alma.qcow2 --net default --import --noautoconsole
virsh list
virsh console <VM_ID>
> ctrl + ]
virsh destroy <VM_ID>
virsh undefine <VM_NAME>
```

5. virt-sysprep, virt-sparsify

```bash
virt-sysprep -a /var/lib/libvirt/images/alma.qcow2
virt-sparsify /var/lib/libvirt/images/alma.qcow2 ~/alma-sealed.qcow2
openstack image create --file ~/alam-sealed.qcow2 --format qcow2 --public alma-sealed

virt-customize -a alma.qcow2 --hostname test.example.com
```



레드햇 계열
---
7.3이전까지

ext4/xfs/btrfs --> ext4/xfs(default)

xfs version
---

SGI, 실리콘 그래픽스에서 사용하던 고성능 파일시스템. 단점은 관리기능이 없음. 


RHEL 7: 4.x(8/9마운트 안됨)
RHEL 8: 5.x(7마운트, 9안됨)
RHEL 9: 6.x(8/9마운트, 10안됨)


[V] XFS 4/5/6(RHLE 6/7/8/9+10)
[ ] 연습문제 303, datacentre(flat, vlan)

## 네트워크 랩


아래 명령어는 컨트롤러에서 수행

```bash
EXTERNAL_ID=$(sudo ovs-vsctl get open . external_ids:ovn-remote | awk -F: '{print $2}')
export NBDB=tcp:${EXTERNAL_ID}:6641
export SBDB=tcp:${EXTERNAL_ID}:6642

alias ovn-sbctl="podman exec ovn_controller ovn-sbctl --db=$SBDB"
alias ovn-nbctl="podman exec ovn_controller ovn-nbctl --db=$NBDB"
alias ovn-trace="podman exec ovn_controller ovn-trace --db=$SBDB"
```


아래 명령어는 컨트롤러에서 수행

```bash
openstack user create --password net1user net1user
openstack project create network-test
openstack role add --user net1user --project network-test admin
cp admin-rc net1user-rc
vi net1user-rc
> OS_USERNAME=net1user
> OS_PASSWORD=net1user
> OS_PROJECT_NAME=network-test
> PS1=....(net1user)

openstack server list --project network-test
```

네트워크 및 기타 자원 생성(컨트롤러)
```bash
openstack network create net1
openstack subnet create --dhcp --network net1 --subnet-range 10.10.10.0/24 net1-subnet
openstack network list --project network-test

openstack router create net1-router

openstack keypair create net1-key > net1-key.pem
openstack image create --file <FILE> net1-image

openstack security group create net1-sec
openstack security group rule create --proto tcp --src-ip 0.0.0.0/0 --dest-port 22 net1-sec
openstack security group rule create --proto tcp --src-ip 0.0.0.0/0 --dest-port 80 net1-sec
```

컨트롤러에서 OVN 자원 확인

```bash
ovn-nbctl show 
ovn-nbctl ls-list
ovn-nbctl lr-list
ovn-nbctl acl list
```

```

# DAY 4


tenant/provider network
---

>The primary difference between tenant networks and provider networks revolves around who provisions them. Provider networks are created by the OpenStack administrator on behalf of tenants and can be dedicated to a particular tenant, shared by a subset of tenants (see RBAC for networks) or shared by all tenants. On the other hand, tenant networks are created by tenants for use by their instances and cannot be shared (based upon default policy settings). 

provider network
---
Provider networks are created by the OpenStack administrator.


tenant network
---
tenants for use by their instances and cannot be shared.

링크 모음
---

[OVN/OVS DB RELAY](https://docs.ovn.org/en/latest/tutorials/ovn-ovsdb-relay.html)

[Deployment Limits for Red Hat OpenStack Platform](https://access.redhat.com/articles/1436373)

[OVN: Open Virtual Network for Open vSwitch](https://www.openvswitch.org/support/slides/OVN-Vancouver.pdf)

[HA for OVN DB servers using pacemaker](https://docs.ovn.org/en/latest/topics/integration.html)

[OVN 디버깅 방법](https://access.redhat.com/documentation/ko-kr/red_hat_openstack_platform/16.2/html/networking_guide/ovn-db-aliases-creating_neutron-troubleshoot)

[ovs-system bridge](https://mail.openvswitch.org/pipermail/ovs-discuss/2013-October/031531.html)

[ML2 Configuration](https://wiki.openstack.org/wiki/Ml2_conf.ini_File)

[오픈스택 서비스 목록](https://www.openstack.org/software/project-navigator/openstack-components#openstack-services)

[OpenStack amphora image build-1](https://docs.openstack.org/octavia/latest/admin/amphora-image-build.html)

[OpenStack amphora image build-2](https://docs.openstack.org/octavia/latest/contributor/specs/version0.5/base-image.html)

[Tenant networks vs. provider networks in the private cloud context](https://superuser.openinfra.dev/articles/tenant-networks-vs-provider-networks-in-the-private-cloud-context/)