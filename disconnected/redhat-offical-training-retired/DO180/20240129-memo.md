# DAY 1


https://rol.redhat.com

메모파일 주소
---
>https://github.com/tangt64/training_memos/
>redhat-offical-training/DO180

랩 아이디/비밀번호
---
- student/student(for OS USER)
- root/redhat(for OS ADM)
- admin/redhatocp(for OCP ADM)
- developer/developer(for OCP USER)

그림파일 주소
---
https://wbd.ms/share/v2/aHR0cHM6Ly93aGl0ZWJvYXJkLm1pY3Jvc29mdC5jb20vYXBpL3YxLjAvd2hpdGVib2FyZHMvcmVkZWVtLzFjYzM5NzZkY2M2ODQxM2RiNjdkZjE2Njc1ZGUxYjZhX0JCQTcxNzYyLTEyRTAtNDJFMS1CMzI0LTVCMTMxRjQyNEUzRF9iMGU0NDdkZS1mOTllLTRhMTEtODM4Yy00MGYwNTM0NDczNzI=


```bash

   OpenShift(Openshift.io API)
   ------------------------------
   |operator| openshift-api-server
   +--------+
   Kubernetes(kubernetes.io API)
   +------+
   |hosted| kubelet
   +------+
   ------------------------------
   RUNTIME(k8s, low level runtime)
    - low level runtime(CRI)
      + containerd
      + crio
    - high level runtime engine(shim)
      + docker
      + podman
   ------------------------------
   O/S(Kernel Module[X])
     - namespace(google,[M])
     - cgroup(google,[M])
     - seccomp(kernel,[M])

* 30(container: 11)

   coreos: os-tree
     - 내용변경 불가
     - 롤링 업데이트(일괄적인 OS버전 및 패키지 관리)
```

https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/install-kubeadm/


```bash

oc login -u<USERNAME> -p<PASSWORD> <URL>:6443

oc new-project <PROJECT>

# backend: operator, k8s/ocp core compo. == namespace
# app, deploy: service application, developer side == project

kubectl create namespace <NAMESPACE>

```

결론은 "레드햇 오픈시프트"만 "프로젝트(openshift.io)"

```bash
   <---- 수행 및 구현 ----           <---- 실행 ----
+---+          +----------------+         +-----+
|POD|          | infra container|         |Pause|
+---+          +----------------+         +-----+
개념, 격리     컨테이너                  애플리케이션

+-----------+         +-----+
| container |<------- | POD | --> 격리
+-----------+  cpu    +-----+
    app        mem     pause
                         - namespace(2: 가상 자원+격리)
                         - cgroup(1: 제한 및 감사(자원))


```

```bash
podman images
podman pull localhost/podman-pause
podman pull docker.io/google/pause
podman images
> [IMAGE_ID]
podman save <IMAGE_ID> -o podman_pod.tar
podman save <IMAGE_ID> -o google_pod.tar

mkdir podman_pod
mkdir google_pod

tar xf podman_pod.tar -C podman_pod
tar xf google_pod.tar -C google_pod

cd podman_pod/
tar xf <모든 tar파일>
> ./catatonit top
cd google_pod/
tar xf <모든 tar파일>
> ./pause
```

레드햇 시험(추천 RHCA)
---
[EX403](https://www.redhat.com/en/services/training/ex403-red-hat-certificate-expertise-deployment-systems-management-exam)
[EX380](https://www.redhat.com/en/services/training/ex380-certified-specialist-openshift-automation-exam)
[EX362](https://www.redhat.com/en/services/training/ex362-red-hat-certified-specialist-identity-management-exam)
[EX240](https://www.redhat.com/en/services/training/ex240-red-hat-certified-specialist-api-management-exam)
[EX404](https://www.redhat.com/en/services/training/rh404-red-hat-satellite-6-administration-with-exam)
[EX188]
[EX280](https://www.redhat.com/en/services/training/red-hat-certified-openshift-administrator-exam)
[EX467](https://www.redhat.com/en/services/training/ex467-red-hat-certified-specialist-managing-automation-ansible-automation-platform-exam?section=objectives)
[EX210](https://www.redhat.com/en/services/training/ex210-red-hat-certified-system-administrator-red-hat-openstack-exam)

```bash

              +-------------------+
              | replicaController | ===> POD * 5
              +-------------------+
                       /         \                 .--- VPA
                      /           \               /
                     /             `------.      .--- HPA
                    /                      \    /
              +------------+             +------------+          +-----+
              | deployment | ----------> | replicaset | -------- | POD |  
              +------------+             +------------+          +-----+
               PodCnt: 10(V-A)               POD * 10
                       10(V-C)               rolling  A(10) -> C(10) 
                     \
                      \
                       \
      +---------+     +---------+        +-------+
      | coredns | --- | service |  <---  | route |
      +---------+     +---------+        +-------+
                                          - ingress

                                   +--------------+
                                   | deployconfig |  
                                   +--------------+

hosted: kubelet
static-pod: apiserver, scheduler, etcd
pod: application container


                 - 모니터링
                 - 프로비저닝
 --- API --->  [ kubelet ]  ---> [ kubernetes-api-server ] ---> [ scheduler ] ---> [ kubelet ] ---> [ node ] 
 <create pod>                                                                                         \
                                                                                                       `---> kube-proxy ---> [ container_runtime ] 

                
           > [ container monitor ]
               lifecycle
  runc --- conmon --- cri-o  [engine]
 [runtime]            podman
(kubernetes)          containerd                                                                                                            

  crun(openshift)
 [runtime]


```

```
 ifcfg-rh
 ifcfg-suse
 ifcfg-debian   ---> netplan(x)          ---> systemd ---> systemd-networkd(o)
 ifcfg-ubuntu        networkmanager(o)
                     wicked(x)
```

[seccomp for kubernetes](https://kubernetes.io/docs/tutorials/security/seccomp/)


# DAY 2

1. namespace: kernel(추상적+장치)
2. namespace: kubernetes(추상적+쿠버네티스 자원 격리)
3. namespace: infra namespace(OCP의 시스템 자원)


## 이미지 빌드 도구

1. podman build = docker build.
2. buildah bud -f Containerfile|Dockerfile.
3. 표준으로 현재는 "Containerfile".
4. CI/CD에서 이미지 빌드 하시는 경우, "buildah"기반으로 권장.
5. "/var/lib/containers/storage".
6. "overlay"디렉터리가 모든 데이터를 가지고 있음. 
7. 데이터는 "backingBlockDev"장치를 통해서 별도의 레이어에 저장.


```bash
vi /etc/containers/registries.conf
registries = ['quay.io', 'local.registries.com']

```

```yaml
/etc/containers/policy.json
---
{
    "default": [
        {
            "type": "insecureAcceptAnything"
        }
    ],
    "transports":
        {
            "docker-daemon":
                {
                    "": [{"type":"insecureAcceptAnything"}]
                }
        }
}
```

```bash
docker search ---> skopeo
podman search 


skopeo list-tags docker://quay.io/centos/centos

podman inspect quay.io/openshifttest/base-alpine
podman pull quay.io/openshifttest/base-alpine
podman inspect quay.io/openshifttest/base-alpine

podman rmi quay.io/openshifttest/base-alpine
skopeo inspect docker://quay.io/openshifttest/base-alpine


oc image <URL>
oc run --image=<URL>

oc new-app <URL>

```

```bash

                            OpenShift ACM
                                 OCM
                                /   \
                               /     \
                              /       \
                             /         \
           .--- project-cluster                 .--- prod-cluster
           |  - CI/CD                           |      - CI/CD(revision1-->2)
           |  - allow(kubectl edit)             |      - denied(kubectl)
        +-----------+                        +-------
        | K8S-C1    |                        | K8S-C2
        +-----------+                        +-------
          - pod             ----------->       - deploy(revision2-->3)
          - deploy(rs)    release              - ingress
          - pv/pvc(sc)
          - daemonset(monitoring)
          - cronjob(logging)

```



```bash

oc describe 
oc logs
oc status



oc describe pod/rhel9-mysql | grep -i ip
> 10.8.0.X
oc run mysqlclient \
--image registry.ocp4.example.com:8443/rhel9/mysql-80:1-237 \
--env MYSQL_ROOT_PASSWORD=redhat123
oc exec -it mysqlclient \
-- mysqlshow -u redhat -p -h 10.8.0.109

## -- 표준 입력 
```




- [kubernetes OVN](https://github.com/ovn-org/ovn-kubernetes)

- [레드햇 이미지 빌드 메뉴얼](https://access.redhat.com/documentation/ko-kr/red_hat_enterprise_linux/8/html/building_running_and_managing_containers/assembly_running-skopeo-buildah-and-podman-in-a-container)
- [dumb init](https://github.com/Yelp/dumb-init)

- [OCP AB, Blue/Green](https://www.youtube.com/watch?v=EEgGaVwDJOU)
- [빌더 이미지 스크래치](https://github.com/containers/buildah/blob/main/docs/tutorials/01-intro.md)

- [루트권한 부분(hosted)](https://access.redhat.com/documentation/ko-kr/red_hat_enterprise_linux/8/html/building_running_and_managing_containers/con_privileged-and-unprivileged-podman-containers_assembly_running-skopeo-buildah-and-podman-in-a-container)

```bash
https://quay.io/repository/sclorg/nginx-120-c9s

quay.io/sclorg/nginx-120-c9s

oc create(kubectl create) == oc new-app
> 자원을 생성하는 명령어. 쿠버네티스 자원 생성 명령어.(CLI)
> 1. pod
> 2. deploy, rs, limit...
> 원격에서 YAML파일을 불러오는 경우.
> oc create -f <FILENAME>.yaml
> oc create -f <URL>

oc apply
> 자원을 생성하는 명령어. 
> YAML기반.
> 리비전 기능이 지원.
> oc apply -f <FILENAME>.yaml
> oc apply -f <URL>
oc run

oc delete all --all

oc create deployment test-nginx-1 --image=quay.io/redhattraining/hello-world-nginx --replicas=10 --dry-run=client -o=yaml > test-nginx-1.yaml
oc apply -f test-nginx-1.yaml

oc create deployment test-nginx-2 --image=quay.io/redhattraining/hello-world-nginx --replicas=20 --dry-run=client -o=yaml > test-nginx-2.yaml
oc apply -f test-nginx-2.yaml
vi test-nginx-2.yaml
>     labels:
>       lab: test3
oc apply -f test-nginx-2.yaml
oc get rs



oc create deployment test-nginx-3 --image=quay.io/redhattraining/hello-world-nginx --replicas=5 --dry-run=client -o=yaml > test-nginx-3.yaml
oc apply -f test-nginx-3.yaml


      cpu overload
      ---------->
oc get pods | grep test-nginx-3         ## 0.116
oc get pods -l=lab=test           ## etcd 
               --- ----
               /     \
              /       `---> value
             /
          key_name
```


```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: nginx-deployment
  labels:
    app: nginx
    type: deployment




spec:
  ## POD[80/TCP]
  ## ReplicaSet  
  replicas: 3
  selector:           ## RS <--- Deployment(Revision 1)
    matchLabels:                                     2
      app: nginx
      test: test                                     3
  template:
    metadata:
      labels:
        app: nginx
    spec:     ## Container
      containers:
      - name: nginx
        image: nginx:1.14.2
        ports:
        - containerPort: 80     ## Network, loopback bind to POD

ENV: 쉘 변수
Label: YAML/ETCD


oc new-app --template mysql-persistent
oc new-app mysql~

```

# DAY 3

[쿠버네티스 클러스터 최대 크기](https://kubernetes.io/docs/setup/best-practices/cluster-large/)

```bash


 | kubernetes |
 +------------+
 | openstack  |

```


- [오픈시프트 클러스터 최대 크기-1](https://www.redhat.com/en/blog/running-2500-pods-per-node-on-ocp-4.13)
- [오픈시프트 클러스터 최대 크기-2](https://www.redhat.com/en/blog/500_pods_per_node)
- [오픈시프트 클러스터 최대 크기-3](https://docs.openshift.com/container-platform/4.8/nodes/nodes/nodes-nodes-managing-max-pods.html)
- [델 k8s/ocp](https://infohub.delltechnologies.com/l/design-guide-red-hat-openshift-container-platform-4-2/introduction-to-hardware-design-5/)



## 템플릿

- [Pod cycle](https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle/)

1. 쿠버네티스에서는 해당 자원이 없음.
2. 쿠버네티스는 helm, kustomize통해서 대신 구현.
3. 템플릿은 오픈 시프트의 고유 자원.
4. 이미지 스트림(is, imagestream)를 활용함.
5. 이미지 스트림 == 컨테이너 이미지 레지스트리 

* crio멈추어도 컨테이너는 그대로 동작(conmon)
* kubelet API조회 및 Pod상태 확인

```bash
           Pod
            |
            |
  [ replication controllers ] --- [ deploymentconifg ]
        /            \
       /              \
    deployment      replicaset
                        |
                        |
                       Pod

             <service>
           - wordpress
           - mysql-persistent
             .
             .
             .------ [ parameter ]
             .
             .
        | template |  ---  [ ImagesStream ]
                                \
             |                   \
             |                     `---> nginx
             |                          apache
             v                          mysql
           [deployment]
           [pv/pvc]
           [secret]
           [configmap]
           ..


oc get is       ## imagestream
```

## 명령어 정리

- [쿠버네티스 명령어 정리-1](https://github.com/dennyzhang/cheatsheet-kubernetes-A4/blob/master/cheatsheet-kubernetes-A4.pdf)

- [쿠버네티스 명령어 정리-2](https://kubernetes.io/docs/reference/generated/kubectl/kubectl-commands#-strong-getting-started-strong-)

- [쿠버네티스 명령어 정리-3](https://kubernetes.io/docs/reference/kubectl/)


## 연습 재료(?)

[오픈시프트 펍](https://github.com/openshift-examples)

## 서비스

```bash
oc create service <RESOURCE_TYPE>

oc new-app --image=nginx
kubectl create deployment test-nginx --image=nginx
oc expose deployment/test-nginx
oc get svc
> test-nginx --> 172.30.X.X
> nginx      --> 172.30.X.X         ## Service network IP
oc get endpoint test-nginx
oc get endpoint nginx
#
# 각 Pod의 아이피(컨테이너 아이피 아님)
# Pod Network IP

                        10.8.X.X/24         172.30.X.X(VIP)
[ container ]   ---     [ POD ]     ---     [ SERVICE ]
                                            clusterIP
                        [ POD ]     ---     [ NAT ]

oc scale --replicas=3 deployment/test-nginx
oc get deploy
oc get endpoint test-nginx

                           = pause --> running     
                        | POD | POD IP: 10.8.X.X/24
                        +-----+   Port: 80, 443, 3306
                       /       \
                      /         \
                    loopback    loopback
                    K: namespace[net]
                   /               \
                [ con1  ]       [ con2 ]    
                  apache         mysql
                  80/TCP         3306/TCP

  ingress | ---> [ SVC ] ---> [ POD ]
                   /
  nginx(SEP) -----'

  haproxy --- {SVC} --- > [ POD ]
 

```

1. [고수준 표준 방화벽](https://firewalld.org/documentation/man-pages/firewalld.dbus.html)
2. [저수준 표준 네트워크 필터링](https://www.netfilter.org/projects/nftables/index.html)

__externalname:__ 외부에 설정 및 구성이 되어 있는 DNS A recode를 통해서 SVC에 접근.
```
 foo.example.com --- [ A IN 192.168.10.100 ]  --- [ SVC ] --- [ POD ]
                          (worker node)
```
__clusterip:__ 쿠버네티스 혹은 오픈 시프트 내부에서 사용하는 아이피. Pod의 엔드포인트 정보를 가지고 있음. (SEP, SVC, POD)

__loadbalancer:__ AWS, GCP에서 제공하는 L/B. 혹은, 여러분들이 물리적으로 구성한 L/B. 혹은 nginx, haproxy같은 L/B. 현재 쿠버네티스 MetalLB를 사용. 
- iptables/nftables(clusterip)통해서 아주 원초적인 L/B를 구성. 

__nodeport:__ 특정 포트번호를 명시 해주면, 모든 노드에 특정 포트를 통해서 서비스(svc, service)에 접근이 가능.

```
192.168.10.100:31000 ---  [ SVC ]  --- [ POD ]
                          nodeport
```

* oc get route: HAProxy기반으로 동작.
* oc get ingress: Kubernetes의 기반의 ingress 서비스 지원(HAproxy, Nginx)
```
kubectl get ingress
            -------
                \
                 `---> Nginx-ingress, HAProxy-ingress
```
[쿠버네티스 서비스 노출](https://kubernetes.io/docs/tutorials/kubernetes-basics/expose/expose-intro/)


[쿠버네티스 튜토리얼 깃헙](https://kubernetes.io/docs/tutorials/kubernetes-basics/expose/expose-intro/)

[제네브 터널링 프로토콜](https://www.redhat.com/en/blog/what-geneve)

1세대(OS의존)
---
LinuxBridge, Mac, iptables, TUN/TAP

2세대(OpenFlow)
---
namespace(veth, vpair)
OpenVSwtich(L2/L3)

3세대(SDN)
---
OVS/OVN(L2/L3/L4)
>https://www.openvswitch.org/
>
OVN: Route, Network, ACL
>https://www.ovn.org/en/


# 마지막날(ㅠㅠ)


```bash
oc new-project test-pod
oc new-app --image=nginx
oc get pods 
oc describe pod/test-pod
oc delete all --all -n default
oc delete pod --all 
oc new-app --image=nginx

```

## ETCD

1. corosync(3대)
2. control-plane x 6
3. worker-node(H/A X)
4. R/S(Recovery)
5. Cluster to Cluster(OCM, ACM)

## scale

1. HPA(옆으로 확장 및 축소, storageclass)
2. VPA(위로 확장 및 축소, pv/pvc)


- [스토리지 클래스](https://kubernetes.io/docs/concepts/storage/storage-classes/)
- [스토리지 클래스 로칼](https://kubernetes.io/docs/concepts/storage/storage-classes/#local)
- [기본 스토리지 클래스](https://kubernetes.io/docs/concepts/storage/storage-classes/#default-storageclass)
- [SC/PV/PVC manual](https://kubernetes.io/docs/tasks/configure-pod-container/configure-persistent-volume-storage/#create-a-persistentvolume)

```yaml
storageClassName: ""
storageClassName: "low"
storageClassName: manual
  annotations:
    storageclass.kubernetes.io/is-default-class: "true"


statefulset: stateful(session, VPA)
-----------
 \
  `---> POD: nginx-1   
             nginx-2
             nginx-3

replicaset: stateless, MSA(API+Token, HPA)
-----------
  \
   `---> POD: nginx-slkjs-kjs82
              nginx-skdiw-82jsk
```

[stateful 예제](https://github.com/devlinx9/k8s_tomcat_custer)

## 설치 명령어 정리

### 우분투 20.04
```bash
sudo hostnamectl set-hostname master.example.com
sudo hostnamectl set-hostname node1.example.com

sudo cat <<EOF | sudo tee /etc/modules-load.d/k8s.conf
overlay
br_netfilter
EOF

sudo modprobe overlay
sudo modprobe br_netfilter

# sysctl params required by setup, params persist across reboots
cat <<EOF | sudo tee /etc/sysctl.d/k8s.conf
net.bridge.bridge-nf-call-iptables  = 1
net.bridge.bridge-nf-call-ip6tables = 1
net.ipv4.ip_forward                 = 1
EOF

# Apply sysctl params without reboot
sudo sysctl --system

lsmod | grep br_netfilter
lsmod | grep overlay
sysctl net.bridge.bridge-nf-call-iptables net.bridge.bridge-nf-call-ip6tables net.ipv4.ip_forward

sudo apt-get update
sudo apt-get install -y apt-transport-https ca-certificates curl
sudo mkdir -m 755 /etc/apt/keyrings

curl -fsSL https://pkgs.k8s.io/core:/stable:/v1.27/deb/Release.key | sudo gpg --dearmor -o /etc/apt/keyrings/kubernetes-apt-keyring.gpg
echo 'deb  [signed-by=/etc/apt/keyrings/kubernetes-apt-keyring.gpg] https://pkgs.k8s.io/core:/stable:/v1.27/deb/ /' |  tee /etc/apt/sources.list.d/kubernetes.list

sudo apt-get update
sudo apt-get install -y kubelet kubeadm kubectl
sudo apt-mark hold kubelet kubeadm kubectl

sudo echo 'deb http://deb.debian.org/debian buster-backports main' > /etc/apt/sources.list.d/backports.list
sudo apt update




## 아래 명령어는 루트에서 실행

```bash
export OS=xUbuntu_20.04
export VERSION=1.27.0

curl -fsSL  https://mirrorcache-jp.opensuse.org/repositories/devel:/kubic:/libcontainers:/stable:/cri-o:/1.27:/1.27.0/xUbuntu_20.04/Release.key | apt-key add -

curl -fsSL  https://mirrorcache-jp.opensuse.org/repositories/devel:/kubic:/libcontainers:/stable/xUbuntu_20.04/Release.key | apt-key add -

echo "deb https://download.opensuse.org/repositories/devel:/kubic:/libcontainers:/stable/$OS/ /" > /etc/apt/sources.list.d/devel:kubic:libcontainers:stable.list
echo "deb https://download.opensuse.org/repositories/devel:/kubic:/libcontainers:/stable:/cri-o:/1.27:/1.27.0/xUbuntu_20.04/ /" > /etc/apt/sources.list.d/devel:kubic:libcontainers:stable:cri-o:$VERSION.list
apt update
apt-get install cri-o cri-o-runc -y

systemctl enable --now crio
systemctl enable --now kubelet

cat <<EOF> /etc/netplan/01-eth1.yaml 
network:
  version: 2
  renderer: networkd
  ethernets:
    enp2s0:
      dhcp4: no
      addresses:
        - 192.168.20.1/24
EOF
netplan apply

cat <<EOF>> /etc/hosts
192.168.90.1 master.example.com master
192.168.90.2 node1.example.com node1
192.168.20.3 node2.example.com node2
EOF

## 만약, firewalld가 설치 되어 있으면 중지

systemctl stop firewalld
systemctl disable firewalld
systemctl is-active firewalld

swapoff -a 
```
## 쿠버네티스 설치

```bash
kubeadm init --apiserver-advertise-address=192.168.20.1 --pod-network-cidr=192.168.0.0/16 --service-cidr=10.90.0.0/16

## 네트워크 구성(calico기반)

kubectl create -f https://raw.githubusercontent.com/projectcalico/calico/v3.24.5/manifests/tigera-operator.yaml
curl https://raw.githubusercontent.com/tangt64/training_memos/main/opensource-101/kubernetes-101/calico-quay-crd.yaml -o calico-quay-crd.yaml 
kubectl apply -f calico-quay-crd.yaml 
```

## 메트릭/역할

```bash
kubectl create -f https://raw.githubusercontent.com/tangt64/training_memos/main/opensource-101/kubernetes-101/files/metrics.yaml
```

## 확인하기(마스터)

```bash
export KUBECONFIG=/etc/kubernetes/admin.conf 
kubectl get nodes
```

## 쿠버네티스 프록시 서비스 및 포트 포워드

```bash
kubectl create ns proxy-nginx-lab
kubectl run proxy-nginx --port=80 --image=nginx -n  ns proxy-nginx-lab
kubectl port-forward pod/proxy-nginx --address=0.0.0.0 8080:80 -n  ns proxy-nginx-lab
```



# 레드햇 계열

## 설치 명령어 정리
## 쿠버네티스 싱글 마스터 + 2노드 클러스터 구성(kubeadm)

- kubespray(ansible)
- kind
- minikube

## 마스터 및 노드 공통 설정

```bash
master/node]# cat <<EOF> /etc/yum.repos.d/kubernetes.repo
[kubernetes]
name=Kubernetes
baseurl=https://pkgs.k8s.io/core:/stable:/v1.26/rpm/
enabled=1
gpgcheck=1
gpgkey=https://pkgs.k8s.io/core:/stable:/v1.26/rpm/repodata/repomd.xml.key
# exclude=kubelet kubeadm kubectl cri-tools kubernetes-cni
EOF
master/node]# dnf search --disableexcludes=kubernetes kubectl kubeadm kubelet 
master/node]# dnf install --disableexcludes=kubernetes kubectl kubeadm kubelet 
master/node]# setenforce 0
master/node]# vi /etc/selinux/config
> permissive
```

```bash
master/node]# systemctl stop firewalld && systemctl disable firewalld
master/node]# swapon -s
master/node]# swapoff -a
master/node]# dnf install tc -y                 ## optional
master/node]# dnf install iproute-tc -y         ## centos-9-stream, optional
```

### hosts A Recode(instead bind)
1. bind(dns) 구성(primary)
2. /etc/hosts A(ipv4),AAAA(ipv6) recode를 구성(backup)

```bash
#
# 내부 아이피로 구성
#
master/node]# cat <<EOF>> /etc/hosts
192.168.90.110 master.example.com master

192.168.90.120 node1.example.com node1
192.168.90.130 node2.example.com node2
EOF
```
### kubelet service

__처음에 동작 시 "activing..."라고 표시가 되는것은 지극히 정상__

```bash
master]# systemctl status kubelet
master]# systemctl enable --now kubelet
```

### crio install(o)

```bash
master/node]# cat <<EOF> /etc/yum.repos.d/libcontainer.repo
[devel_kubic_libcontainers_stable]
name=devel_kubic_libcontainers_stable
type=rpm-md
baseurl=https://download.opensuse.org/repositories/devel:/kubic:/libcontainers:/stable/CentOS_9_Stream/
gpgcheck=1
gpgkey=https://download.opensuse.org/repositories/devel:/kubic:/libcontainers:/stable/CentOS_9_Stream/repodata/repomd.xml.key
enabled=1
EOF


master/node]# cat <<EOF> /etc/yum.repos.d/crio_stable.repo
[crio]
name=cri-o for derivatives RHEL
type=rpm-md
baseurl=https://download.opensuse.org/repositories/devel:/kubic:/libcontainers:/stable:/cri-o:/1.24:/1.24.6/CentOS_8/
gpgcheck=1
gpgkey=https://download.opensuse.org/repositories/devel:/kubic:/libcontainers:/stable:/cri-o:/1.24:/1.24.6/CentOS_8/repodata/repomd.xml.key
enabled=1
EOF
master/node]# dnf install cri-o -y
master/node]# systemctl enable --now crio
master/node]# systemctl is-active crio


```
### modules

```bash
master/node]# modprobe br_netfilter    ## bridge for iptables or nftables, L2/L3
master/node]# modprobe overlay         ## cotainer image for UFS(overlay2), Disk(UFS)
master/node]# cat <<EOF> /etc/modules-load.d/k8s-modules.conf
br_netfilter
overlay
EOF
```

### kenrel parameter
```bash
master/node]# cat <<EOF> /etc/sysctl.d/k8s-mod.conf
> net.bridge.bridge-nf-call-iptables=1    ## container ---> link ---> tap ---> bridge
> net.ipv4.ip_forward=1                   ## pod <---> svc
> net.bridge.bridge-nf-call-ip6tables=1   ## ipv6
> EOF
sysctl --system                           ## 재부팅 없이 커널 파라메타 수정하기
dracut -f                   ## ramdisk 갱신
```

### kubeadm init as single controller role node

```bash
master]# kubeadm init --apiserver-advertise-address=192.168.90.110 --pod-network-cidr=192.168.0.0/16 --service-cidr=10.90.0.0/16
master]# systemctl is-active kubelet                ## active
master]# crictl ps 
```
### 초기화 순서 및 방법

노드에서 마스터 순서로 리셋.
```bash
@master]# kubeadm reset --force 
@node]# kubeadm reset --force
```

### kubeadm join(single)

```bash
@master]# KUBECONFIG=/etc/kubernetes/admin.conf kubeadm token create --print-join-command
```

### node join

```bash
kubeadm join 192.168.90.110:6443 --token yspx54.k2076yehis972cng \
        --discovery-token-ca-cert-hash sha256:4743574ead43b14374be00496294bcb5ee85a3967724c0c3464ca9dcb576fb27
kubectl get nodes    
```
### 터널링 네트워크 구성

```bash
kubectl create -f https://raw.githubusercontent.com/projectcalico/calico/v3.26.1/manifests/tigera-operator.yaml
wget https://raw.githubusercontent.com/tangt64/duststack-k8s-auto/master/roles/cni/cni-calico/templates/custom-resources.yaml
vi custom-resources.yaml
> cidr: 192.168.0.0/16
kubectl apply -f custom-resources.yaml
```

#### 메트릭/역할(임시)
```bash
kubectl create -f https://raw.githubusercontent.com/tangt64/training_memos/main/opensource/kubernetes-101/files/metrics.yaml
kubectl label node node1.example.com node-role.kubernetes.io/worker=worker
kubectl label node node2.example.com node-role.kubernetes.io/worker=worker
kubectl top nodes
kubectl get nodes
```
- 노드 1번에 쿠버네티스/CRIO/모듈/커널 파라메타/방화벽/kubelet 등 서비스 설정
- 마스터에서 token create로 조인 명령어 생성 후, 노드1에서 실행

#### 확인하기(마스터)
```bash
export KUBECONFIG=/etc/kubernetes/admin.conf 
kubectl get nodes
```



