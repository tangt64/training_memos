# DAY1

## 강사 정보

- __이름:__ 최국현
- __메일주소:__ tang/앙/linux.com
- __점심시간:__ 
- __쉬는시간:__ 

> https://github.com/tangt64/training_memos/
> LinuxFoundation/

__메모 주소:__ [링크](https://github.com/tangt64/training_memos/blob/main/LinuxFoundation/)

## Registration Link

__주소:__ [등록링크](https://linux.thoughtindustries.com/redeem)

__코드:__ lfs458fastlanekorea20231010

## Course Survey Link 

__주소__: [서베이 주소](https://www.surveymonkey.com/r/KK7Z3SR?course=LFS458_20231010_PART_VIRT_FASTLANEKOREA)


### 쿠버네티스/런타임 소개

CSI: Container Storage Interface (CSI) Specification 
> NFS(nfs 4.x(pnfs, ganesha-nfs))
> san/nas
> shared type FS

CNI: Container Network Interface
> vxlan, geneve, vlan...
> flanned, calico...

OCI: Open Container Initiative
> Runtime Specification (runtime-spec), 
> the Image Specification (image-spec, docker-image --> OCI Image) 
>> Dockerfile --> Containerfile
>> docker build Dockefile --> buildah bud 
> Distribution Specification (distribution-spec). 
>> /var/lib/containers/
>> /run/containers/
> The Runtime Specification outlines how to run a “filesystem bundle” 
>> Overlay2 Filesystem

CRI: Container Runtime Interface
1. docker-shim(cri-docker, keyword: docker-cri) 
2. CRI-O
> Google, IBM/Redhat, SuSE
3. containerd(CRI adapter, standard container runtime) 


https://www.ianlewis.org/assets/images/768/runtimes.png


```bash
dnf install epel-release -y
dnf search tmux
dnf install tmux -y
vi ~/.tmux.conf
> set -g mouse on
dnf search podman                                          ## podman container engine
dnf install podman podman-compose podman-docker -y
systemctl enable --now podman                            ## podman.service for API
podman pod ls
podman container ls
ps -ef | grep podman
ps -ef | grep runc

podman run -d --name httpd quay.io/centos7/httpd-24-centos7 

cd /var/lib/containers/
> stoage
podman container ls
cd overlay-containers
ls -l 
> [CONTAINER_ID_DIRECTORY]
ps -ef | grep httpd
ps -ef | grep conmon
lsns
```

CR: deployment, replicaset, pod...
CRD: configmap, secret...

### 랩 설치 준비

[설치 명령어 모음](https://raw.githubusercontent.com/tangt64/training_memos/main/LinuxFoundation/LFS458/command-collection.md)

```bash
setenforce 0
hostnamectl set-hostname bare.cka.example.com
dnf install git ansible -y
git clone https://github.com/tangt64/duststack-k8s-auto.git
cd duststack-k8s-auto
ssh-keygen -t rsa -N '' -f ~/.ssh/id_rsa
vi /etc/ssh/sshd_config
> PermitRootLogin yes

systemctl reload sshd
ssh-copy-id root@127.0.0.1

vi playbooks/lab-provisioning.yaml
> remote_user: tang --> root
./provin-k8s.sh

virsh list
> k8s_utility_node
virsh domifaddr 40 
virsh domifaddr k8s_utility_node
> 192.168.122.135/24
ssh root@192.168.122.200                                             ## 암호는 kubernetes
```

## utility node(임시 마스터)

```bash
systemctl stop firewalld
systemctl disable firewalld
systemctl is-active firewalld
setenforce 0
getenforce
cat <<EOF>> /etc/hosts
192.168.90.200 master.example.com master
192.168.90.250 node2.example.com node2
EOF
hostnamectl set-hostname master.example.com

curl https://download.opensuse.org/repositories/devel:/kubic:/libcontainers:/stable/CentOS_7/devel:kubic:libcontainers:stable.repo -o /etc/yum.repos.d/libcontainers.repo
curl https://download.opensuse.org/repositories/devel:/kubic:/libcontainers:/stable:/cri-o:/1.28:/1.28.1/CentOS_7/devel:kubic:libcontainers:stable:cri-o:1.28:1.28.1.repo -o /etc/yum.repos.d/crio.repo
yum repolist
yum search cri-o
yum install cri-o -y
systemctl enable --now crio

cat <<EOF | sudo tee /etc/yum.repos.d/kubernetes.repo
[kubernetes]
name=Kubernetes
baseurl=https://pkgs.k8s.io/core:/stable:/v1.28/rpm/
enabled=1
gpgcheck=1
gpgkey=https://pkgs.k8s.io/core:/stable:/v1.28/rpm/repodata/repomd.xml.key
exclude=kubelet kubeadm kubectl cri-tools kubernetes-cni
EOF
yum install -y kubelet kubeadm kubectl --disableexcludes=kubernetes
systemctl enable --now kubelet

cat <<EOF | sudo tee /etc/modules-load.d/k8s.conf
overlay
br_netfilter
EOF
modprobe overlay
modprobe br_netfilter

cat <<EOF | sudo tee /etc/sysctl.d/k8s.conf
net.bridge.bridge-nf-call-iptables  = 1
net.bridge.bridge-nf-call-ip6tables = 1
net.ipv4.ip_forward                 = 1
EOF
sysctl --system

kubeadm init                                                    ## 테스트 및 확인 
export KUBECONFIG=/etc/kubernetes/admin.conf
kubectl get pods -A
kubeadm reset --force 

kubeadm init --apiserver-advertise-address=192.168.90.200 --pod-network-cidr=192.168.0.0/16 --service-cidr=10.90.0.0/16 

## --pod-networ-cidr: POD에서 사용하는 터널링 네트워크 대역. 일반적으로 터링과 같은 대역을 사용한다. 랩에서는 eth1
## --service-cidr: 쿠버네티스 서비스 영역(NAT)에서 사용하는 아이피 대역
## 위의 두개 아이피는 서로 겹치면 안됨

kubeadm token create --print-join-commnad

# node2(임시로 utility master와 연결 시도)

## 필수 준비 사항 
1. /etc/hosts(node2)
127.0.0.1   localhost localhost.localdomain localhost4 localhost4.localdomain4
::1         localhost localhost.localdomain localhost6 localhost6.localdomain6
192.168.90.200 master.example.com master
192.168.90.250 node2.example.com node2

2. hostnamectl set-hostname node2.example.com
3. 마스터와 동일하게 커널 모듈 및 파라메타 설정이 필요

nodeX]# kubeadm join 192.168.90.200:6443 --token etyc27.bx82vp6zyfx83wc4 --discovery-token-ca-cert-hash sha256:8eba1a36e4c528ea60b6942b6abe1a52b0cf06aa70892eb61a289e78906857da 
```
# DAY 2

마스터 혹은 노드 초기화는 무조건 "kubeadm reset --force"

```bash
export KUBECONFIG=/etc/kubernetes/admin.conf
kubectl get nodes
kubeadm token list 
kubeadm token create --print-join-command
```

CRIO vs Containerd
----
https://gist.github.com/kunalkushwaha/66629a90e0f8f5cc5dc512ef1c346f2f


랩 파일
---
https://github.com/tangt64/training_memos/blob/main/LinuxFoundation/LFS458/materials/LFS458_V1.28.1u1_SOLUTIONS.tar.xz


## 명령어 사용 및 서비스 설명

```bash
## 1
export KUBECONFIG=/etc/kubernetes/admin.conf

## 2
mkdir ~/.kube/
cp /etc/kubernetes/admin.conf ~/.kube/config

## 3
apt list | grep bash-completion
dnf list installed | grep bash-completion

## 4
kubeadm completion bash > 
                      zsh 
kubectl completion bash >
                      zsh

## 데비안/레드햇 계열

kubectl completion bash > ~/.bashrc      ## 권장하지 않음

kubectl completion bash > /etc/bash_completion.d/kubectl
kubeadm completion bash > /etc/bash_completion.d/kubeadm
complete -rp

```
### etcd


#### for rocky
```bash
dnf search centos-release-openstack
dnf install centos-release-openstack-antelope
dnf search etcd
dnf install etcd -y
ETCDCTL_API=3 etcdctl --endpoints=https://192.168.90.100:2379 \
  --cacert=/etc/kubernetes/pki/etcd/ca.crt  --cert=/etc/kubernetes/pki/etcd/peer.crt --key=/etc/kubernetes/pki/etcd/peer.key \
  snapshot save /root/snapshot.db
```

```bash
apt install etcd-client -y
cat /etc/kubernetes/manifests/etcd.yaml
> listen-client-urls
> trusted-ca-file
> peer-key-file
> peer-cert-file

ETCDCTL_API=3 etcdctl --endpoints=https://192.168.90.100:2379 \
  --cacert=/etc/kubernetes/pki/etcd/ca.crt  --cert=/etc/kubernetes/pki/etcd/peer.crt --key=/etc/kubernetes/pki/etcd/peer.key \
  snapshot save /root/snapshot.db

file /root/snapshot.db
```


# DAY 3

https://kubesec.io/

```bash
dnf install podman -y
apt search podman

podman pull quay.io/redhattraining/hello-world-nginx
podman images

podman run -d --name helloworld-nginx-test1 --rm -p 80:8080 quay.io/redhattraining/hello-world-nginx
podman container ls                                      ## container ls -a
podman stop helloworld-nginx-test1
podman rm -f helloworld-nginx-test1

podman pod ls

podman run -d --pod new:pod_nginx --name helloworld-nginx-test1 --rm -p 80:8080 quay.io/redhattraining/hello-world-nginx
podman images

podman pod ls
podman container ls

podman save k8s.gcr.io/pause:3.5 -o podman-pause.tar
mkdir tmp-podman-pause/
tar xf podman-pause.tar -C tmp-podman-pause/
cd tmp-podman-pause/

podman inspect pod 159ec7c54eec
podman inpsect container 5f327714e53e

podman pod ls
> POD_ID
podman generate kube <POD_ID> --service
podman generate kube 159ec7c54eec --service > nginx_test_kube.yaml
kubectl create -f nginx_test_kube.yaml

apt install skopeo

podman save <ID> -o <IMG_FILE_NAME>.tar
skopeo copy  docker://registry.k8s.io/kube-apiserver:v1.27.6 docker-archive:kube-apiserver-v1.27.6.tar:registry.k8s.io/kube-apiserver:v1.27.6
skopeo sync --src docker --dest docker 
skopeo sync --src docker --dest dir
```

```bash
kubectl debug node/node1.example.com --image=centos --copy-to=debug -it
```

```bash
kubectl debug pod/nginx --copy-to=debug-nginx-2 --image=centos -it
```

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: nginx
spec:
  shareProcessNamespace: true
  containers:
  - name: nginx
    image: nginx
  - name: shell
    image: busybox:1.28
    command: ["sleep", "3600"]
    securityContext:
      capabilities:
        add:
        - SYS_PTRACE
    stdin: true
    tty: true

````

```bash
kubectl create ns cj-nginx
kubectl create cronjob cj-nginx --image=nginx --schedule="* * * * *" --dry-run=client -o=yaml --namespace=cj-nginx

kubectl create ns j-date
kubectl create job j-date --image=busybox --dry-run=client -o=yaml --namespace=j-date -- date

```

```yaml
cat pv.yaml 
apiVersion: v1
kind: PersistentVolume
metadata:
  name: task-pv-volume
  labels:
    type: local
spec:
  storageClassName: manual
  capacity:
    storage: 3Gi
  accessModes:
    - ReadWriteOnce
  hostPath:
    path: "/tmp/"
````

```yaml
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: task-pv-claim
spec:
  storageClassName: manual
  accessModes:
    - ReadWriteMany
  resources:
    requests:
      storage: 1Gi
```

```yaml

apiVersion: v1
kind: Pod
metadata:
  name: task-pv-pod
spec:
  volumes:
    - name: task-pv-storage
      persistentVolumeClaim:
        claimName: task-pv-claim   ## /tmp
  containers:
    - name: task-pv-container
      image: quay.io/redhattraining/hello-world-nginx
      ports:
        - containerPort: 80
          name: "http-server"
      volumeMounts:
        - mountPath: "/usr/share/nginx/html"
          name: task-pv-storage
```
# DAY 4

```bash
ETCDCTL_API=3 etcdctl --endpoints=https://192.168.90.100:2379 \
  --cacert=/etc/kubernetes/pki/etcd/ca.crt  --cert=/etc/kubernetes/pki/etcd/peer.crt --key=/etc/kubernetes/pki/etcd/peer.key \
  etcdctl  get --keys-only --prefix=true "/registry/namespaces/"
```

```bash
kubectl create deployment nginx-v1 --image=quay.io/redhattraining/hello-world-nginx --port=8080 --replicas=10 --dry-run=client -o=yaml > nginx-v1.yaml
kubectl create deployment nginx-v1 --image=quay.io/redhattraining/hello-world-nginx --port=8080 --replicas=10
kubectl expose deployment/nginx-v1 --name=http-nginx-v1 --type=NodePort --target-port=2323 

kubectl run pod-nginx --image=quay.io/redhattraining/hello-world-nginx --port=8080 --expose 
kubectl run pod-nginx-none-expose --image=quay.io/redhattraining/hello-world-nginx --port=8080
kubectl run pod-nginx-none-expose-none --image=quay.io/redhattraining/hello-world-nginx 

kubectl get pod
kubectl get svc


kubectl expose pod/pod-nginx --type=NodePort 
kubectl expose pod/pod-nginx --name=pod-nginx-nodeport --type=NodePort 
kubectl expose pod/pod-nginx --name=pod-nginx-nodeport-custom --type=NodePort --target-port=30232

kubectl expose <DEPLOYMENT>
                  <POD>       pod/pod-nginx --type NodePort 
                                                                  --port
                                                                  --protocol
                                                                  --external-ip
                                                                  --target-port
```