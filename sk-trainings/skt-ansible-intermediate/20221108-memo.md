# day 1


## 과정설명


## 강사정보

최국현/(tang@linux.com)

메모 내용은 아래 주소에서 확인이 가능.
[메모](https://github.com/tangt64/training_memos/blob/main/sk-trainings/skt-ansible-intermediate/20221108-memo.md)


https://github.com/tangt64/training_memos




## 약간 변경된 내용

```bash
sudo dnf config-manager --add-repo=https://download.docker.com/linux/centos/docker-ce.repo
```
현재 'crio'의 저장소가 올바르게 동작하지 않아서 "containerd"기반으로 런타임 구성.
동작에는 큰 문제가 없으니, "containerd"에 맞게 저장소 및 설정파일 수정 후 구성

기본 스켈레톤(Skeleton)은 아래 주소에서 내려받기 혹은 확인이 가능.

[스켈레톤](https://github.com/tangt64/training_memos/tree/main/sk-trainings/skt-ansible-intermediate)

배포받은 가상머신은 "con.dustbox.kr"에서 확인이 가능하며, 각각 가상머신은 "console.dustbox.kr"에서 접근이 가능.

"root/centos"이며, "console.dustbox.kr" 및 "con.dustbox.kr"에 접근 시 사용하는 계정은 skt1~10번까지, 암호는 동일하게 "skt1234"이다.

접근 시 사용하는 콘솔은 아무거나 사용하여도 상관이 없음.


* con.dustbox.kr
  sktXX
  skt1234

* console.dustbox.kr
  sktXX
  skt1234



## kubefed


https://github.com/kubernetes-sigs/kubefed
>
>클러스 연합 구성해주는 API
>관리도구도 바닐라 버전(오리지날)를 통해서 개발이 될 예정.
>올 7월달? 이 정도에 더 이상 개발을 진행하지 않기로 결정. 

* kube-virt
  - https://kubevirt.io/

* karmada
  - 클러스터 단위
  - https://github.com/karmada-io/karmada
  - 
* OCM(Redhat ACM)
  - ACM + 부과적인 정책 기능 및 감사..(NIST)
  - 클러스터 단위(지역(국가별))로 컨테이너 및 가상머신 배포시 고려가 많이 됨.
    + kube-virt(qemu+kvm+libvirtd)
                   ----
                   +POD
  - https://open-cluster-management.io/
  



## 런타임


### CRI-O
https://cri-o.io/

### Containerd
https://containerd.io/

```bash
dnf config-manager --add-repo=https://download.docker.com/linux/centos/docker-ce.repo
dnf install containerd -y
systemctl start containerd
systemctl enable --now containerd
```

"containerd"의 관리 명령어는 'ctr'.

```bash
ctr containers ls
```


쿠버네티스 저장소 파일 생성
```bash
cat <<EOF | sudo tee /etc/yum.repos.d/kubernetes.repo
[kubernetes]
name=Kubernetes
baseurl=https://packages.cloud.google.com/yum/repos/kubernetes-el7-\$basearch
enabled=1
gpgcheck=1
gpgkey=https://packages.cloud.google.com/yum/doc/rpm-package-key.gpg
exclude=kubelet kubeadm kubectl
EOF
# Set SELinux in permissive mode (effectively disabling it)
sudo setenforce 0
sudo sed -i 's/^SELINUX=enforcing$/SELINUX=permissive/' /etc/selinux/config

sudo yum install -y kubelet kubeadm kubectl --disableexcludes=kubernetes

sudo systemctl enable --now kubelet
```

```
firewall-cmd --add-port="6443/tcp"
             --add-port="10240/tcp"
```

```
systemctl is-active containerd
systemctl enabled --now containerd
containerd config default > /etc/containerd/config.toml
systemctl restart containerd
kubeadm init --cri-socket=/var/run/containerd/containerd.sock
--------------------------



kubeadm init --cri-socket="<SOCKET LOCATE>"
                           /run/containerd/containerd.sock
mkdir -p $HOME/.kube
sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
sudo chown $(id -u):$(id -g) $HOME/.kube/config                           
```



https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/install-kubeadm/


## 제작준비


커널 파라메터
```
net.bridge.bridge-nf-call-iptables  = 1
net.ipv4.ip_forward                 = 1
net.bridge.bridge-nf-call-ip6tables = 1
```
커널 모듈
```
br_netfilter
overlay
```


```bash 
cp -a /root/training_memos/sk-trainings/skt-ansible-intermediate/skeleton_directory ~/
cd /root/skeleton_directory/library

cat ../inventory
[all:vars]
ansible_password=centos
ansible_user=root

[master]
192.168.90.231 nodename=master1.skt14.com k8s_ip4_address=10.10.10.167

[worker]
192.168.90.225   nodename=node1.skt14.com k8s_ip4_address=10.10.10.3
192.168.90.60    nodename=node2.skt14.com k8s_ip4_address=10.10.10.166

cat ssh.yaml
#key: "{{ lookup('file', '/home/' + lookup('env', 'USER') + '/.ssh/id_rsa.pub') }}"
key: "{{ lookup('file', '/root/' + '/.ssh/id_rsa.pub') }}"

cat hosts.j2
{{ hostvars[host]['ansible_default_ipv4']['address'] }} {{ hostvars[host]['ansible_fqdn'] }} {{ hostvars[host]['ansible_hostname'] }}

ansible-playbook ssh.yaml 
ansible-playbook deploy_hosts_j2.yaml
```


### modules vs roles + plugins


ansible, ansible-playbook: 일종의 모듈런처 및 파라메타 게이트웨이(API)
  ansible-tower: API ---> parameter ---> ansible-playbook
                -----
                hooking  ---> postgresql

- roles: YAML + Jinja2 + pyLib로 동작하는 작업 셋트
- modules: 파이썬 기반으로 구성이 되어있는 앤서블 모듈(python 프로그램)
    posix, core: /usr/lib/python3.9/site-packages/ansible/modules
    collection: 앤서블 사이트나 혹은 밴더사에 제공하는 것들이 보통..

- plugins: 앤서블에서 데이터 핸들링을 좀 더 수월(??)하기 위해서 추가된 기능



### Role and Roles

roles: 일반적으로 앤서블에서 명시하는 "role"디렉터리 이름.
       - 복수형으로 "roles"라는 이름으로 많이 구성함. 
       - "ansible.cfg"에서 선언이 가능
         + [defaults]
         + roles_path=<DIRECTORY>

role: 사용 혹은 구성할 작업의 역할이름
       - 예를들어 패키지 설치 관련 role, 일반적으로 yum, package모듈 기반으로 작업

__role조건__
특정 작업이 __"하나의 묶음으로 구성한 경우"__, __역할(role)__ 될 수도 있음.
```
 roles/
       os-network  ---> "role"에서 사용할 이름(=namespace)
                        "role"자원들은 "role"끼리 관여하지 않는다.
                 /tasks/
                        main.yaml
                         \
                          `- task_a.yaml, import_: 메모리에 미리 적제
                          `- task_b.yaml, include_: 문법이 호출이 되었을 때 메모리에 적제
                 /files/
                        \
                         `- material1.conf
                         `- text.txt
                         `- data.dat

                 /templates/
                            httpd.conf.j2
                            vsftpd.conf.j2
                 /vars/
                       main.yaml
                 
                 /defaults/
                           main.yaml
```

9, os-repositories
2,10,13 os-packages
5,6,7,8 os-kernel
1,2,3,4 os-security 
11,12, core-runtime
14, os-service 


```yaml

- hosts: all

  tasks:
(1)  - name: SELinux     
    selinux:
      policy: targeted
      state: permissive

(2)  - name: install the firewalld package
    package:
      name: firewalld
      state: present

(3)  - name: start and enabled to the firewalld
    systemd:
      name: firewalld
      state: started
      enabled: yes

(4)  - name: add the kubernetes ports to firewalld {{ inventory_hostname }}
    firewalld:
      port: "{{ item }}/tcp"
      permanent: yes
      state: enabled
    loop:
      - 6443
      - 10240

(5)  - name: copy a kernel module loadup config file
    copy:
      src: files/k8s-modules.conf
      dest: /etc/modules-load.d/k8s-modules.conf

(6)  - name: restart systemd-modules-load.service
    systemd:
      name: systemd-modules-load
      state: restarted

(7)  - name: copy a kernel parameter config file for iptables(nftables)
    copy:
      src: files/99-k8s.conf
      dest: /etc/sysctl.d/99-k8s.conf

(8)  - name: apply the kernel parameter on {{ inventory_hostname }} 
    command: sysctl -p --system

(9)  - name: copy a kubernete/containerd repository file for YUM(dnf-3)
    copy:
      src: files/{{ item }}
      dest: /etc/yum.repos.d/{{ item }}
    loop:
      - kubernetes.repo
      - containerd.repo

(10)  - name: install containerd package on {{ inventory_hostname }}
    package:
      name: containerd.io
      state: present

(11)  - name: regenerate to containerd.io config.toml
    command: containerd config default > /etc/containerd/config.toml

(12)  - name: start and enabled to containertd.service
    systemd:
      name: containerd
      state: started
      enabled: yes

(13)  - name: install kubernetes packages on {{ inventory_hostname }}
    yum:
      name: "{{ item }}"
      state: present
      disable_excludes: all
    loop:
      - kubelet
      - kubeadm
      - kubectl

(14)  - name: start kubelet.service on {{ inventory_hostname }}
    systemd:
      name: kubelet
      state: started
      enabled: yes
```


https://github.com/dense-analysis/ale



# day 2

```bash
grep -Ri "  systemd:" .

./core-runtime/tasks/main.yaml:  systemd:
./os-kernel/tasks/main.yaml:  systemd:
./os-security/tasks/main.yaml:  systemd:
./os-service/tasks/main.yaml:  systemd:
```


```

kubeadm init --apiserver-advertise-address --cri-socket --image-repository --pod-network-cidr --service-cidr --service-dns-domain

```


### master 서버

"docker"에서 제공하는 "containerd"는 "pod cni"파일이 없음. 

```bash
cat <<EOF> /etc/cni/net.d/10-containerd-net.conflist
{
  "cniVersion": "1.0.0",
  "name": "containerd-net",
  "plugins": [
    {
      "type": "bridge",
      "bridge": "cni0",
      "isGateway": true,
      "ipMasq": true,
      "promiscMode": true,
      "ipam": {
        "type": "host-local",
        "ranges": [
          [{
            "subnet": "10.88.0.0/16"
          }],
          [{
            "subnet": "2001:4860:4860::/64"
          }]
        ],
        "routes": [
          { "dst": "0.0.0.0/0" },
          { "dst": "::/0" }
        ]
      }
    },
    {
      "type": "portmap",
      "capabilities": {"portMappings": true}
    }
  ]
}
EOF
scp /etc/cni/net.d/10-containerd-net.conflist root@node1:/etc/cni/net.d/10-containerd-net.conflist
scp /etc/cni/net.d/10-containerd-net.conflist root@node2:/etc/cni/net.d/10-containerd-net.conflist
ssh root@node1 "systemctl restart containerd"   ## 1,2번 둘다
kubeadm init
kubeadm token create --print-join-command
mkdir -p $HOME/.kube
cp -i /etc/kubernetes/admin.conf $HOME/.kube/config   ## 재설치를 하면 인증서 다시 복사
kubectl get nodes
```


### node
```bash
## 노드에도 containetrd에서 사용할 "/etc/cni/net.d/10-containerd-net.conflist"존재해야 됨
kubeadm join 192.168.90.184:6443 --token dn5zph.wsr2pskhnjbgjdem --discovery-token-ca-cert-hash sha256:583a319a6ac342cec61f14ba40eb973906a73875c178cad21aa447449162cdfd

```


https://raw.githubusercontent.com/containerd/containerd/main/script/setup/install-cni